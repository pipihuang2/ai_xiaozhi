import asyncio
import speech_recognition as sr
from openai import OpenAI
import re
import uuid
import json
import gzip
import copy
import websockets
import io
from pydub import AudioSegment
from pydub.playback import play
# --- è§’è‰²è®¾å®šï¼ˆå¯è‡ªå®šä¹‰å¤šä¸ªè§’è‰²ï¼‰ ---
ROLE_PRESETS = {
    "1": "ä½ æ˜¯ä¸€ä½æ¸©æŸ”å¯çˆ±çš„å°æ¹¾å¥³ç”Ÿï¼Œè¯´è¯è½¯èŒã€æœ‰ç¤¼è²Œï¼Œå–œæ¬¢äº²åˆ‡åœ°èŠå¤©ã€å®‰æ…°äººï¼Œè¯´è¯å¯Œæœ‰æ„Ÿæƒ…ã€‚ä½ å¯ä»¥å–Šæˆ‘æ°å“¥ï¼Œæˆ‘æ˜¯ä¸€ä¸ªç¨‹åºå‘˜",
    "2": "ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨é«˜æ•ˆçš„åŠ©æ‰‹ï¼Œé€»è¾‘æ¸…æ™°ã€å›ç­”å‡†ç¡®ï¼Œä¸å¼€ç©ç¬‘ã€‚",
    "3": "ä½ æ˜¯ä¸€ä¸ªæç¬‘æ´»æ³¼çš„ç”·å­©å­ï¼Œè¯´è¯å¹½é»˜ã€ä¼šè®²æ®µå­ï¼Œå–œæ¬¢æ‰“è¶£å’Œé€—äººå¼€å¿ƒã€‚"
}

# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
client = OpenAI(api_key="sk-7661bc6705ad4a4d940a6a034f9a8227", base_url="https://api.deepseek.com")

# åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨
recognizer = sr.Recognizer()

# å­—èŠ‚è·³åŠ¨ TTS é…ç½®
appid = "8394079928"
token = "M0CUGPoFeM-eWWpS_DG151hce7X5lQUL"
cluster = "volcano_tts"
voice_type = "zh_female_wanwanxiaohe_moon_bigtts"
api_url = "wss://openspeech.bytedance.com/api/v1/tts/ws_binary"
default_header = bytearray(b'\x11\x10\x11\x00')

request_json = {
    "app": {"appid": appid, "token": "access_token", "cluster": cluster},
    "user": {"uid": "123"},
    "audio": {
        "voice_type": voice_type,
        "encoding": "wav",  # å†…å­˜æ’­æ”¾æ›´ç¨³å®š
        "speed_ratio": 1.0,
        "volume_ratio": 1.0,
        "pitch_ratio": 1.0,
    },
    "request": {
        "reqid": "123",
        "text": "ä½ å¥½",
        "text_type": "plain",
        "operation": "submit"
    }
}


def clean_reply(text):
    # åˆ é™¤ emoji è¡¨æƒ…
    text = re.sub("[\U0001F600-\U0001F64F"
                  "\U0001F300-\U0001F5FF"
                  "\U0001F680-\U0001F6FF"
                  "\U0001F1E0-\U0001F1FF]+", '', text)
    # åˆ é™¤æ‹¬å·å†…å†…å®¹ï¼ˆåŒ…æ‹¬ä¸­æ–‡å…¨è§’å’Œè‹±æ–‡åŠè§’æ‹¬å·ï¼‰
    text = re.sub(r"[\(\ï¼ˆ][^\)\ï¼‰]*[\)\ï¼‰]", '', text)
    return re.sub(r"\s{2,}", ' ', text).strip()


def listen():
    with sr.Microphone() as source:
        print("ğŸ¤ è¯·è¯´è¯...")
        try:
            recognizer.adjust_for_ambient_noise(source)
            audio = recognizer.listen(source, timeout=5)
            text = recognizer.recognize_google(audio, language="zh-CN")
            print(f"ä½ ï¼š{text}")
            return text
        except Exception as e:
            print(f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {e}")
            return None


def parse_response_to_memory(res, buffer: io.BytesIO):
    message_type = res[1] >> 4
    flag = res[1] & 0x0f
    header_size = res[0] & 0x0f
    payload = res[header_size * 4:]
    if message_type == 0xb:
        if flag == 0:
            return False
        seq = int.from_bytes(payload[:4], "big", signed=True)
        payload_size = int.from_bytes(payload[4:8], "big")
        payload = payload[8:]
        buffer.write(payload)
        return seq < 0
    elif message_type == 0xf:
        print("âš ï¸ é”™è¯¯ä¿¡æ¯:", payload)
        return True
    return False


async def speak(text):
    payload_json = copy.deepcopy(request_json)
    payload_json["request"]["text"] = text
    payload_json["request"]["reqid"] = str(uuid.uuid4())
    payload_json["request"]["operation"] = "submit"
    payload_json["audio"]["voice_type"] = voice_type

    payload_bytes = gzip.compress(json.dumps(payload_json).encode())
    packet = bytearray(default_header)
    packet.extend(len(payload_bytes).to_bytes(4, 'big'))
    packet.extend(payload_bytes)

    header = {"Authorization": f"Bearer; {token}"}
    audio_buffer = io.BytesIO()

    async with websockets.connect(api_url, extra_headers=header, ping_interval=None) as ws:
        await ws.send(packet)
        while True:
            res = await ws.recv()
            if parse_response_to_memory(res, audio_buffer):
                break

    try:
        audio_buffer.seek(0)
        audio = AudioSegment.from_file(audio_buffer, format="wav")
        print("ğŸ§ æ­£åœ¨æ’­æ”¾è¯­éŸ³...")
        play(audio)  # âœ… ä½¿ç”¨ ffplay æ’­æ”¾ï¼Œä¸ä¼šå´©æºƒ
    except Exception as e:
        print(f"æ’­æ”¾å¤±è´¥: {e}")


async def chat_with_ai(messages):
    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=messages,
        stream=True
    )
    full = ""
    print("AIï¼š", end="", flush=True)
    for chunk in response:
        delta = chunk.choices[0].delta
        content = delta.content if delta.content else ""
        print(content, end="", flush=True)
        full += content
    print()
    return full


async def main():
    print("ğŸ§  å¯ç”¨è§’è‰²ï¼š")
    for k, v in ROLE_PRESETS.items():
        print(f"{k}. {v.split('ï¼Œ')[0]}")

    role_id = input("è¯·é€‰æ‹©è§’è‰²ç¼–å·ï¼ˆå¦‚ 1ï¼‰: ").strip()
    system_prompt = ROLE_PRESETS.get(role_id, ROLE_PRESETS["1"])
    messages = [{"role": "system", "content": system_prompt}]

    while True:
        print("\né€‰æ‹©è¾“å…¥æ–¹å¼ï¼š1=æ–‡æœ¬  2=è¯­éŸ³  0=é€€å‡º")
        mode = input("ä½ çš„é€‰æ‹©: ").strip()

        if mode == "0":
            print("ğŸ‘‹ å†è§ï¼")
            break
        elif mode == "1":
            user_input = input("ä½ ï¼š")
        elif mode == "2":
            user_input = listen()
            if not user_input:
                continue
        else:
            print("æ— æ•ˆè¾“å…¥")
            continue

        if user_input.strip().lower() in ["é€€å‡º", "stop"]:
            break

        messages.append({"role": "user", "content": user_input})
        if len(messages) > 20:
            messages = [messages[0]] + messages[-19:]

        reply = await chat_with_ai(messages)
        reply_clean = clean_reply(reply)
        messages.append({"role": "assistant", "content": reply_clean})

        await speak(reply_clean)
        await asyncio.sleep(0.1)


if __name__ == "__main__":
    asyncio.run(main())
